## ポジネガ辞書の限界（皮肉/婉曲/文脈依存）

このスコアリングは **辞書（PN/Wago）に含まれる語/フレーズの一致 + 否定反転（window）** だけで判定する。
そのため、文章全体の意味理解や文脈推定が必要なケースは苦手。

### 皮肉（逆の感情を言う）
- 例: 「ご立派なことで」「（滑稽で）ウケる」
- 表層の評価語がポジでも、意図がネガの場合は判別できない

### 婉曲（遠回しな不満/当てこすり）
- 例: 「別にいいんじゃない？」「そういう感じなんだね」「なるほどね（察し）」
- 露骨な評価語が含まれない/弱いと **中立** になりやすい

### 文脈依存（対象・状況で極性が変わる）
- 例: 「やばい」「流石」「天才」
  - ポジ/ネガ両方で使われるため、辞書一致だけでは安定しない
- 例: 「重い」「刺さる」「無理」
  - 話題（UI/人間関係/体調など）によって意味が変わる

### その他（仕様上の限界）
- 多義語・否定のスコープ
  - 例: 「最高とは言ってない」「嫌いじゃないわけではない」など、否定が多重/係り受けが必要な文は精度が落ちる
- 絵文字/記号/語尾のニュアンス
  - 例: 「草」「w」「…」「🥺」などは辞書では扱いにくい
- 長文ほどノイズが増える
  - 0スコア語（中立語）が多数ヒットすると平均が薄まり、意図した温度感が出にくい場合がある
  - MVP開発中に中立語の扱いについて検討すること(中立語を評価語に含めない、中立語のうちポジネガ分析に必要な語はユーザー辞書に定義するなど)

> NOTE: MVP時点ではPoCが目的。<br>
> PoC確立後に、AIによる精密な感情分類（皮肉検出・文脈推定）に移行する。

## 辞書運用（容量/更新/速度）の見通しメモ

### 容量
- ベース辞書（PN/Wago）は固定ファイルを参照する前提（Docker内 `/opt/sentiment_lex/`）
- 追加運用するのは **ユーザー辞書 `sentiment_userdic/user.pn`** のみ
  - 表記ゆれ（うれしい/嬉しい 等）や俗語（しか勝たん 等）などSNSで多用される表現かつポジネガ分析に影響が高そうな語を中心に追加する方針

### 更新
- ユーザー辞書は **リポジトリ管理（TSV）**
- 反映はコンテナ再起動でOK（辞書が遅延ロード/初回参照で読み込みのため）
    ```sh
    make dev-restart
    ```
- 方針:
  - まずは「誤判定の原因になった語」や「未収録で取りこぼした語」だけを追加
  - 追加したら `script/sentiment_test_score_cases` のテストケースに1行足して再確認する

### 速度
- 想定ボトルネックは以下の順になりやすい
  1) MeCab tokenize（形態素解析）
  2) Wagoのフレーズ探索（最大5語の最長一致）
  3) PNの単語参照（Hash参照なので軽い）
- 対策（現状実装の方針）
  - Wagoは **最大5語まで**に制限（6語以上は一致しにくく、辞書内でも少数）
  - 対象品詞（名詞/形容詞/動詞/副詞）だけ探索して無駄を減らす
  - `covered_by_hit` で重複カウントを防ぎ、探索を早期に打ち切る
- 全体モジュール完成後に localprod / 本番相当環境で速度計測しボトルネックを確認し調整する予定

### 運用ルール（迷ったときの判断基準）
- 「辞書に追加する」優先:
  - SNSで頻出、かつスコアに影響が大きい（例: まずい、微妙、しか勝たん）
  - 表記ゆれで取りこぼしている（例: うれしい/嬉しい）
- 「追加しない」判断:
  - 低頻度で、形態素分割や文脈依存が強すぎて運用コストが高い
  - 例: 古めの慣用句や皮肉/婉曲系（辞書追加しても解決しにくい）

> NOTE: ユーザー辞書の精度を高めようとすると切りがないため、<br>
> MVP時点では最低限の追加にとどめ、運用しながら徐々に拡張する。
